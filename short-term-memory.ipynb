{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df010fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the capital of France?', additional_kwargs={}, response_metadata={}, id='07983e37-dc57-4a15-af10-6f608af5bc51'),\n",
       "  AIMessage(content='The capital of France is **Paris**.', additional_kwargs={}, response_metadata={'model': 'gpt-oss:120b-cloud', 'created_at': '2025-10-15T07:15:03.484878158Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4154706830, 'load_duration': None, 'prompt_eval_count': 79, 'prompt_eval_duration': None, 'eval_count': 48, 'eval_duration': None, 'model_name': 'gpt-oss:120b-cloud', 'model_provider': 'ollama'}, id='lc_run--34a1ed28-06af-40c1-9318-e87fc1252875-0', usage_metadata={'input_tokens': 79, 'output_tokens': 48, 'total_tokens': 127})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.messages import HumanMessage,AIMessage,SystemMessage,ToolMessage\n",
    "model=ChatOllama(model=\"gpt-oss:120b-cloud\")\n",
    "agent=create_agent(model,tools=[],checkpointer=InMemorySaver())\n",
    "human_message=HumanMessage(\"What is the capital of France?\")\n",
    "messages=[human_message]\n",
    "agent.invoke({\"messages\":messages},{\"configurable\":{\"thread_id\":\"1\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9da331",
   "metadata": {},
   "source": [
    "In production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aec12cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.postgres import PostgresSaver  \n",
    "\n",
    "DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n",
    "with PostgresSaver.from_conn_string(DB_URI) as checkpointer:\n",
    "    agent = create_agent(\n",
    "        model,\n",
    "        [],\n",
    "        checkpointer=checkpointer,  \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2709df",
   "metadata": {},
   "source": [
    "customizing agent memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5a51e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import AgentMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "class CustomAgentState(AgentState):  \n",
    "    user_id: str\n",
    "    preferences: dict\n",
    "\n",
    "class StateExtensionMiddleware(AgentMiddleware[CustomAgentState]):\n",
    "    state_schema = CustomAgentState  \n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    [],\n",
    "    middleware=[StateExtensionMiddleware()],  \n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "config={\"configurable\":{\"thread_id\":\"1\"}}\n",
    "\n",
    "# Custom state can be passed in invoke\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "    \"user_id\": \"user_123\",  \n",
    "    \"preferences\": {\"theme\": \"dark\"}  \n",
    "}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e6cdd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hello', additional_kwargs={}, response_metadata={}, id='3aefe263-0004-4bab-9adb-2ca5b39145c1'),\n",
       "  AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'model': 'gpt-oss:120b-cloud', 'created_at': '2025-10-15T07:53:14.42424749Z', 'done': True, 'done_reason': 'stop', 'total_duration': 853763214, 'load_duration': None, 'prompt_eval_count': 73, 'prompt_eval_duration': None, 'eval_count': 42, 'eval_duration': None, 'model_name': 'gpt-oss:120b-cloud', 'model_provider': 'ollama'}, id='lc_run--9b6086c9-093c-42fb-acb7-66633a9a4e37-0', usage_metadata={'input_tokens': 73, 'output_tokens': 42, 'total_tokens': 115})],\n",
       " 'user_id': 'user_123',\n",
       " 'preferences': {'theme': 'dark'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1de1ac7",
   "metadata": {},
   "source": [
    "Trim messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db544456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I don’t have any information about your name. If you’d like me to address you by name, just let me know what it is!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n================================== Ai Message ==================================\\n\\nYour name is Bob. You told me that earlier.\\nIf you'd like me to call you a nickname or use a different name, just say the word.\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import before_model\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "@before_model\n",
    "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return None  # No changes needed\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[],\n",
    "    middleware=[trim_messages]\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n",
    "agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "\n",
    "final_response[\"messages\"][-1].pretty_print()\n",
    "\"\"\"\n",
    "================================== Ai Message ==================================\n",
    "\n",
    "Your name is Bob. You told me that earlier.\n",
    "If you'd like me to call you a nickname or use a different name, just say the word.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee7958d",
   "metadata": {},
   "source": [
    "Delete messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e61407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import RemoveMessage  \n",
    "\n",
    "def delete_messages(state):\n",
    "    messages = state[\"messages\"]\n",
    "    if len(messages) > 2:\n",
    "        # remove the earliest two messages\n",
    "        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:2]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2976c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "\n",
    "def delete_messages(state):\n",
    "    return {\"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d7a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import after_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "@after_model\n",
    "def delete_old_messages(state: AgentState, runtime: Runtime) -> dict | None:\n",
    "    \"\"\"Remove old messages to keep conversation manageable.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    if len(messages) > 2:\n",
    "        # remove the earliest two messages\n",
    "        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:2]]}\n",
    "    return None\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    \"openai:gpt-5-nano\",\n",
    "    tools=[],\n",
    "    system_prompt=\"Please be concise and to the point.\",\n",
    "    middleware=[delete_old_messages],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"hi! I'm bob\"}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    print([(message.type, message.content) for message in event[\"messages\"]])\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    print([(message.type, message.content) for message in event[\"messages\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc6a78b",
   "metadata": {},
   "source": [
    "summarize messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f237bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You told me your name is **Bob**. How can I assist you today, Bob?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n================================== Ai Message ==================================\\n\\nYour name is Bob!\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_ollama import ChatOllama\n",
    "checkpointer = InMemorySaver()\n",
    "model=ChatOllama(model=\"gpt-oss:120b-cloud\")\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=model,\n",
    "            max_tokens_before_summary=4000,  # Trigger summarization at 4000 tokens\n",
    "            messages_to_keep=20,  # Keep last 20 messages after summary\n",
    "        )\n",
    "    ],\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n",
    "agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "\n",
    "final_response[\"messages\"][-1].pretty_print()\n",
    "\"\"\"\n",
    "================================== Ai Message ==================================\n",
    "\n",
    "Your name is Bob!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b428192d",
   "metadata": {},
   "source": [
    "access memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6342749c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_agent() got an unexpected keyword argument 'state_schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m     user_id = state[\u001b[33m\"\u001b[39m\u001b[33muser_id\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mUser is John Smith\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_id == \u001b[33m\"\u001b[39m\u001b[33muser_123\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mUnknown user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m agent = \u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mget_user_info\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_schema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCustomState\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m result = agent.invoke({\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mlook up user information\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33muser_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser_123\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     26\u001b[39m })\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(result[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m].content)\n",
      "\u001b[31mTypeError\u001b[39m: create_agent() got an unexpected keyword argument 'state_schema'"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.tools import InjectedState\n",
    "from langchain_ollama import ChatOllama\n",
    "model=ChatOllama(model=\"gpt-oss:120b-cloud\")\n",
    "\n",
    "class CustomState(AgentState):\n",
    "    user_id: str\n",
    "\n",
    "def get_user_info(\n",
    "    state: Annotated[CustomState, InjectedState]\n",
    ") -> str:\n",
    "    \"\"\"Look up user info.\"\"\"\n",
    "    user_id = state[\"user_id\"]\n",
    "    return \"User is John Smith\" if user_id == \"user_123\" else \"Unknown user\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_user_info],\n",
    "    state_schema=CustomState,\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": \"look up user information\",\n",
    "    \"user_id\": \"user_123\"\n",
    "})\n",
    "print(result[\"messages\"][-1].content)\n",
    "# > User is John Smith."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b738e3f",
   "metadata": {},
   "source": [
    "write short-term memory from tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fb13507",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_agent() got an unexpected keyword argument 'state_schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m     user_name = state[\u001b[33m\"\u001b[39m\u001b[33muser_name\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHello \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m!\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m agent = \u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mopenai:gpt-5-nano\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mupdate_user_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreet\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_schema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCustomState\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext_schema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCustomContext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m agent.invoke(\n\u001b[32m     48\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgreet the user\u001b[39m\u001b[33m\"\u001b[39m}]},\n\u001b[32m     49\u001b[39m     context=CustomContext(user_id=\u001b[33m\"\u001b[39m\u001b[33muser_123\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     50\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: create_agent() got an unexpected keyword argument 'state_schema'"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from langchain.tools import InjectedToolCallId, InjectedState\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.messages import ToolMessage\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langgraph.runtime import get_runtime\n",
    "from langgraph.types import Command\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class CustomState(AgentState):  \n",
    "    user_name: str\n",
    "\n",
    "class CustomContext(BaseModel):\n",
    "    user_id: str\n",
    "\n",
    "def update_user_info(\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId],\n",
    ") -> Command:\n",
    "    \"\"\"Look up and update user info.\"\"\"\n",
    "    runtime = get_runtime(CustomContext)  \n",
    "    user_id = runtime.context.user_id\n",
    "    name = \"John Smith\" if user_id == \"user_123\" else \"Unknown user\"\n",
    "    return Command(update={\n",
    "        \"user_name\": name,\n",
    "        # update the message history\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                \"Successfully looked up user information\",\n",
    "                tool_call_id=tool_call_id\n",
    "            )\n",
    "        ]\n",
    "    })\n",
    "\n",
    "def greet(\n",
    "    state: Annotated[CustomState, InjectedState]\n",
    ") -> str:\n",
    "    \"\"\"Use this to greet the user once you found their info.\"\"\"\n",
    "    user_name = state[\"user_name\"]\n",
    "    return f\"Hello {user_name}!\"\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5-nano\",\n",
    "    tools=[update_user_info, greet],\n",
    "    state_schema=CustomState,\n",
    "    context_schema=CustomContext,  \n",
    ")\n",
    "\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"greet the user\"}]},\n",
    "    context=CustomContext(user_id=\"user_123\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dba8f3",
   "metadata": {},
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d71d191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the weather in SF?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (d471943b-1128-45e5-bd6b-ad7e38317dea)\n",
      " Call ID: d471943b-1128-45e5-bd6b-ad7e38317dea\n",
      "  Args:\n",
      "    city: San Francisco\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "The weather in San Francisco is always sunny!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure thing, John Smith! The weather in San Francisco is currently **sunny**. Enjoy the bright skies!\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import AnyMessage\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langgraph.runtime import get_runtime\n",
    "from typing import TypedDict\n",
    "\n",
    "\n",
    "class CustomContext(TypedDict):\n",
    "    user_name: str\n",
    "\n",
    "\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather in a city.\"\"\"\n",
    "    return f\"The weather in {city} is always sunny!\"\n",
    "\n",
    "\n",
    "@dynamic_prompt\n",
    "def dynamic_system_prompt(request: ModelRequest) -> str:\n",
    "    user_name = request.runtime.context[\"user_name\"]\n",
    "    system_prompt = f\"You are a helpful assistant. Address the user as {user_name}.\"\n",
    "    return system_prompt\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[dynamic_system_prompt],\n",
    "    context_schema=CustomContext,\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    context=CustomContext(user_name=\"John Smith\"),\n",
    ")\n",
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f6bd6d",
   "metadata": {},
   "source": [
    "before model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbfa20a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I don’t have any information about your name. If you’d like to share it, feel free to let me know!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n================================== Ai Message ==================================\\n\\nYour name is Bob. You told me that earlier.\\nIf you'd like me to call you a nickname or use a different name, just say the word.\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import before_model\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "\n",
    "@before_model\n",
    "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return None  # No changes needed\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[],\n",
    "    middleware=[trim_messages]\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n",
    "agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "\n",
    "final_response[\"messages\"][-1].pretty_print()\n",
    "\"\"\"\n",
    "================================== Ai Message ==================================\n",
    "\n",
    "Your name is Bob. You told me that earlier.\n",
    "If you'd like me to call you a nickname or use a different name, just say the word.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feecb7c9",
   "metadata": {},
   "source": [
    "after model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "682a20d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import after_model\n",
    "from langgraph.runtime import Runtime\n",
    "\n",
    "@after_model\n",
    "def validate_response(state: AgentState, runtime: Runtime) -> dict | None:\n",
    "    \"\"\"Remove messages containing sensitive words.\"\"\"\n",
    "    STOP_WORDS = [\"password\", \"secret\"]\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if any(word in last_message.content for word in STOP_WORDS):\n",
    "        return {\"messages\": [RemoveMessage(id=last_message.id)]}\n",
    "    return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5-nano\",\n",
    "    tools=[],\n",
    "    middleware=[validate_response],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
