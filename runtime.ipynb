{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c10a4dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='bfbbee17-af73-47b9-9595-a9504c07af1d'),\n",
       "  AIMessage(content='I’m sorry, but I don’t have any information about your name. If you’d like to share it, feel free to let me know!', additional_kwargs={}, response_metadata={'model': 'gpt-oss:120b-cloud', 'created_at': '2025-10-17T02:34:16.079093438Z', 'done': True, 'done_reason': 'stop', 'total_duration': 778127494, 'load_duration': None, 'prompt_eval_count': 76, 'prompt_eval_duration': None, 'eval_count': 90, 'eval_duration': None, 'model_name': 'gpt-oss:120b-cloud', 'model_provider': 'ollama'}, id='lc_run--29faaec9-6646-4cde-889f-21f661271bd2-0', usage_metadata={'input_tokens': 76, 'output_tokens': 90, 'total_tokens': 166})]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain_ollama import ChatOllama\n",
    "model=ChatOllama(model=\"gpt-oss:120b-cloud\")  \n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_name: str\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    context_schema=Context  \n",
    ")\n",
    "\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n",
    "    context=Context(user_name=\"John Smith\")  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112a9714",
   "metadata": {},
   "source": [
    "inside tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b09894c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ToolRuntime' from 'langchain.tools' (d:\\SourceCode-2\\langchain-alpha1\\.venv\\Lib\\site-packages\\langchain\\tools\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataclass\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tool, ToolRuntime  \n\u001b[32m      4\u001b[39m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mContext\u001b[39;00m:\n\u001b[32m      6\u001b[39m     user_id: \u001b[38;5;28mstr\u001b[39m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'ToolRuntime' from 'langchain.tools' (d:\\SourceCode-2\\langchain-alpha1\\.venv\\Lib\\site-packages\\langchain\\tools\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.tools import tool, ToolRuntime  \n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def fetch_user_email_preferences(runtime: ToolRuntime[Context]) -> str:  \n",
    "    \"\"\"Fetch the user's email preferences from the store.\"\"\"\n",
    "    user_id = runtime.context.user_id  \n",
    "\n",
    "    preferences: str = \"The user prefers you to write a brief and polite email.\"\n",
    "    if runtime.store:  \n",
    "        if memory := runtime.store.get((\"users\",), user_id):  \n",
    "            preferences = memory.value[\"preferences\"]\n",
    "\n",
    "    return preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab17dd24",
   "metadata": {},
   "source": [
    "inside middleware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5139014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing request for user: John Smith\n",
      "Completed request for user: John Smith\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='c238e61d-7b2e-499b-ac9f-587657ed6c51'),\n",
       "  AIMessage(content='I don’t have any information about your name. If you’d like me to refer to you by a particular name, just let me know!', additional_kwargs={}, response_metadata={'model': 'gpt-oss:120b-cloud', 'created_at': '2025-10-17T02:34:46.060798017Z', 'done': True, 'done_reason': 'stop', 'total_duration': 834406190, 'load_duration': None, 'prompt_eval_count': 76, 'prompt_eval_duration': None, 'eval_count': 75, 'eval_duration': None, 'model_name': 'gpt-oss:120b-cloud', 'model_provider': 'ollama'}, id='lc_run--7b8b80d1-06eb-4f1a-9720-ff02b8a80160-0', usage_metadata={'input_tokens': 76, 'output_tokens': 75, 'total_tokens': 151})]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain.messages import AnyMessage\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest, before_model, after_model\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_ollama import ChatOllama\n",
    "model=ChatOllama(model=\"gpt-oss:120b-cloud\")\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_name: str\n",
    "\n",
    "# Dynamic prompts\n",
    "@dynamic_prompt\n",
    "def dynamic_system_prompt(request: ModelRequest) -> str:\n",
    "    user_name = request.runtime.context.user_name  \n",
    "    system_prompt = f\"You are a helpful assistant. Address the user as {user_name}.\"\n",
    "    return system_prompt\n",
    "\n",
    "# Before model hook\n",
    "@before_model\n",
    "def log_before_model(state: AgentState, runtime: Runtime[Context]) -> dict | None:  \n",
    "    print(f\"Processing request for user: {runtime.context.user_name}\")  \n",
    "    return None\n",
    "\n",
    "# After model hook\n",
    "@after_model\n",
    "def log_after_model(state: AgentState, runtime: Runtime[Context]) -> dict | None:  \n",
    "    print(f\"Completed request for user: {runtime.context.user_name}\")  \n",
    "    return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[dynamic_system_prompt, log_before_model, log_after_model],  \n",
    "    context_schema=Context\n",
    ")\n",
    "\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n",
    "    context=Context(user_name=\"John Smith\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
