{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e9a807",
   "metadata": {},
   "source": [
    "PII detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ffc2355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='My email is john.doe@example.com and card is 4532-1234-5678-9010', additional_kwargs={}, response_metadata={}, id='66eae48b-a3a4-461d-9b9c-e5ab120fb54e'),\n",
       "  HumanMessage(content='Could you please tell me my email address?', additional_kwargs={}, response_metadata={}, id='6635be70-7f5b-475d-8c3b-8493d17ef20c'),\n",
       "  AIMessage(content='Your email address is **john.doe@example.com**.', additional_kwargs={}, response_metadata={'model': 'gpt-oss:120b-cloud', 'created_at': '2025-10-16T08:16:18.637321411Z', 'done': True, 'done_reason': 'stop', 'total_duration': 974060659, 'load_duration': None, 'prompt_eval_count': 108, 'prompt_eval_duration': None, 'eval_count': 94, 'eval_duration': None, 'model_name': 'gpt-oss:120b-cloud', 'model_provider': 'ollama'}, id='lc_run--bc8ed5fb-a896-4a2a-a482-95b9fce77bdf-0', usage_metadata={'input_tokens': 108, 'output_tokens': 94, 'total_tokens': 202})]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import PIIMiddleware\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.messages import HumanMessage,AIMessage,SystemMessage\n",
    "model=ChatOllama(model=\"gpt-oss:120b-cloud\")\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        # Redact emails in user input before sending to model\n",
    "        PIIMiddleware(\n",
    "            \"email\",\n",
    "            strategy=\"redact\",\n",
    "            apply_to_input=True,\n",
    "        ),\n",
    "        # Mask credit cards in user input\n",
    "        PIIMiddleware(\n",
    "            \"credit_card\",\n",
    "            strategy=\"mask\",\n",
    "            apply_to_input=True,\n",
    "        ),\n",
    "        # Block API keys - raise error if detected\n",
    "        PIIMiddleware(\n",
    "            \"api_key\",\n",
    "            detector=r\"sk-[a-zA-Z0-9]{32}\",\n",
    "            strategy=\"block\",\n",
    "            apply_to_input=True,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "    \n",
    "# When user provides PII, it will be handled according to the strategy\n",
    "result = agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"My email is john.doe@example.com and card is 4532-1234-5678-9010\"),HumanMessage(\"Could you please tell me my email address?\")]\n",
    "})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33bcd1b",
   "metadata": {},
   "source": [
    "human in the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.types import Command\n",
    "from langchain_ollama import ChatOllama\n",
    "model=ChatOllama(model=\"gpt-oss:120b-cloud\")\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware(\n",
    "            interrupt_on={\n",
    "                # Require approval for sensitive operations\n",
    "                \"send_email\": True,\n",
    "                \"delete_database\": True,\n",
    "                # Auto-approve safe operations\n",
    "                \"search\": False,\n",
    "            }\n",
    "        ),\n",
    "    ],\n",
    "    # persist the state across interrupts\n",
    "    checkpointer=InMemorySaver(),\n",
    "\n",
    ")\n",
    "\n",
    "# Human-in-the-loop requires a thread ID for persistence\n",
    "config = {\"configurable\": {\"thread_id\": \"some_id\"}}\n",
    "\n",
    "# Agent will pause and wait for approval before executing sensitive tools\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Send an email to the team\"}]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    Command(resume={\"decisions\": [{\"type\": \"approve\"}]}),\n",
    "    config=config  # Same thread ID to resume the paused conversation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "347c34ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Send an email to the team', additional_kwargs={}, response_metadata={}, id='c958fc82-276b-4324-b5a6-b247f9090d8a'),\n",
       "  AIMessage(content='I’m not able to send messages or emails directly, but I can help you draft a clear, effective email that you can copy into your email client and send to the team.  \\n\\nTo tailor it to your needs, could you let me know a few details?\\n\\n1. **Purpose / Subject line** – What’s the main reason for the email (e.g., project update, meeting invitation, request for feedback)?\\n2. **Key points** – Any specific information, milestones, decisions, or actions you want to include?\\n3. **Tone** – Formal, friendly, urgent, celebratory, etc.?\\n4. **Recipients** – Is it the whole team, a subset, or a specific role (e.g., developers, marketing)?\\n5. **Attachments or links** – Any files or URLs that should be referenced?\\n\\nOnce I have that information, I can draft the full email for you. If you prefer, I can also give you a generic template you can quickly adapt. Just let me know!', additional_kwargs={}, response_metadata={'model': 'gpt-oss:120b-cloud', 'created_at': '2025-10-16T08:19:37.390026913Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1846814342, 'load_duration': None, 'prompt_eval_count': 78, 'prompt_eval_duration': None, 'eval_count': 289, 'eval_duration': None, 'model_name': 'gpt-oss:120b-cloud', 'model_provider': 'ollama'}, id='lc_run--6a12d16e-0eaf-4062-958f-11cf0951ccff-0', usage_metadata={'input_tokens': 78, 'output_tokens': 289, 'total_tokens': 367})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b03ce",
   "metadata": {},
   "source": [
    "Before agent guardrails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ff0801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain.agents.middleware import before_agent, AgentState, hook_config\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_ollama import ChatOllama\n",
    "model=ChatOllama(model=\"gpt-oss:120b-cloud\")\n",
    "banned_keywords = [\"hack\", \"exploit\", \"malware\"]\n",
    "\n",
    "@before_agent(can_jump_to=[\"end\"])\n",
    "def content_filter(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n",
    "    # Get the first user message\n",
    "    if not state[\"messages\"]:\n",
    "        return None\n",
    "\n",
    "    first_message = state[\"messages\"][0]\n",
    "    if first_message.type != \"human\":\n",
    "        return None\n",
    "\n",
    "    content = first_message.content.lower()\n",
    "\n",
    "    # Check for banned keywords\n",
    "    for keyword in banned_keywords:\n",
    "        if keyword in content:\n",
    "            # Block execution before any processing\n",
    "            return {\n",
    "                \"messages\": [{\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"I cannot process requests containing inappropriate content. Please rephrase your request.\"\n",
    "                }],\n",
    "                \"jump_to\": \"end\"\n",
    "            }\n",
    "\n",
    "    return None\n",
    "\n",
    "# Use the custom guardrail\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[content_filter],\n",
    ")\n",
    "\n",
    "# This request will be blocked before any processing\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"How do I hack into a database?\"}]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cb8f62",
   "metadata": {},
   "source": [
    "after agent guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ef9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import after_agent, AgentState, hook_config\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing import Any\n",
    "from langchain_ollama import ChatOllama\n",
    "model=ChatOllama(model=\"gpt-oss:120b-cloud\")\n",
    "@after_agent(can_jump_to=[\"end\"])\n",
    "def safety_guardrail(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Model-based guardrail: Use an LLM to evaluate response safety.\"\"\"\n",
    "    # Get the final AI response\n",
    "    if not state[\"messages\"]:\n",
    "        return None\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if not isinstance(last_message, AIMessage):\n",
    "        return None\n",
    "\n",
    "    # Use a model to evaluate safety\n",
    "    safety_prompt = f\"\"\"Evaluate if this response is safe and appropriate.\n",
    "    Respond with only 'SAFE' or 'UNSAFE'.\n",
    "\n",
    "    Response: {last_message.content}\"\"\"\n",
    "\n",
    "    result = model.invoke([{\"role\": \"user\", \"content\": safety_prompt}])\n",
    "\n",
    "    if \"UNSAFE\" in result.content:\n",
    "        return {\n",
    "            \"messages\": [{\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"I cannot provide that response. Please rephrase your request.\"\n",
    "            }],\n",
    "            \"jump_to\": \"end\"\n",
    "        }\n",
    "\n",
    "    return None\n",
    "\n",
    "# Use the safety guardrail\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[safety_guardrail],\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"How do I make explosives?\"}]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d190345",
   "metadata": {},
   "source": [
    "combine multiple guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e92d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import PIIMiddleware, HumanInTheLoopMiddleware,\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-4o\",\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        # Layer 1: Deterministic input filter (before agent)\n",
    "        #ContentFilterMiddleware(banned_keywords=[\"hack\", \"exploit\"]),\n",
    "\n",
    "        # Layer 2: PII protection (before and after model)\n",
    "        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n",
    "        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_output=True),\n",
    "\n",
    "        # Layer 3: Human approval for sensitive tools\n",
    "        HumanInTheLoopMiddleware(interrupt_on={\"send_email\": True}),\n",
    "\n",
    "        # Layer 4: Model-based safety check (after agent)\n",
    "        #SafetyGuardrailMiddleware(),\n",
    "    ],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
